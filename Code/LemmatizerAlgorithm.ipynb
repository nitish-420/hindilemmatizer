{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X5QmbeErxRfE",
        "outputId": "b7fe29c8-790a-42d6-fd9d-7781a966f95d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import re\n",
        "import pkg_resources\n",
        "\n",
        "globalPrefixWordsSet = set()\n",
        "globalRootWordsSet = set()\n",
        "globalSuffixWordsSet = set()\n",
        "\n",
        "data_path = '/content/drive/MyDrive/CollabData/Lemmatizer/FinalData/data.csv'\n",
        "with open(data_path, encoding='utf-8') as f:\n",
        "  reader=csv.reader(f)\n",
        "  for row in reader:\n",
        "    globalPrefixWordsSet.add(row[1])\n",
        "    globalRootWordsSet.add(row[2])\n",
        "    globalSuffixWordsSet.add(row[3])\n",
        "\n",
        "  f.close()\n",
        "\n",
        "\n",
        "directRoots = dict()\n",
        "\n",
        "direct_path = '/content/drive/MyDrive/CollabData/Lemmatizer/FinalData/direct.csv'\n",
        "with open(direct_path, encoding='utf-8') as f:\n",
        "  reader=csv.reader(f)\n",
        "  for row in reader:\n",
        "    directRoots[row[0]] = row[1]\n",
        "\n",
        "  f.close()\n",
        "\n",
        "\n",
        "totalWords = set()\n",
        "\n",
        "total_path = '/content/drive/MyDrive/CollabData/Lemmatizer/FinalData/totalWords.txt'\n",
        "with open(total_path, encoding='utf-8') as f:\n",
        "  data = f.readlines()\n",
        "  for i in range(len(data)):\n",
        "    totalWords.add(data[i].strip())\n",
        "  f.close()\n",
        "\n",
        "\n",
        "globalPrefixWordsSet.discard(\"\")\n",
        "globalRootWordsSet.discard(\"\")\n",
        "globalSuffixWordsSet.discard(\"\")"
      ],
      "metadata": {
        "id": "L9GKHWfTDoax"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re \n",
        "alreadyLemmatizedWords = dict()\n",
        "# Here comes real algorithm\n",
        "class WordLemmatizer:\n",
        "  \n",
        "  def __init__(self, word):\n",
        "    self.word = word\n",
        "    self.inflectedWord = list(word)\n",
        "    self.possibleRootWords = set()\n",
        "  \n",
        "  def lemmatize(self):\n",
        "    if (len(self.word)<3):\n",
        "      '''\n",
        "        done this because बुरा is giving बु which is not a root word, so length check is made\n",
        "      '''\n",
        "      return self.word\n",
        "\n",
        "    return self.step1()\n",
        "  \n",
        "  def step1(self):\n",
        "\n",
        "    for r in range(1,len(self.word)):\n",
        "      tempWord = self.word[:r+1]\n",
        "      if tempWord in globalRootWordsSet and len(tempWord)>1:\n",
        "        self.possibleRootWords.add(tempWord)\n",
        "\n",
        "    if(len(self.possibleRootWords)):\n",
        "      return self.finalReturn()\n",
        "    \n",
        "    return self.step2()\n",
        "  \n",
        "  def step2(self):  \n",
        "\n",
        "    for l in range(2,len(self.word)):\n",
        "      if self.word[l:] in globalSuffixWordsSet and len(self.word[l:])>1 and (self.word[:l] in totalWords or self.word[:l] in globalRootWordsSet):\n",
        "        self.possibleRootWords.add(WordLemmatizer(self.word[:l]).lemmatize())    \n",
        "      \n",
        "    if(len(self.possibleRootWords)):\n",
        "      return self.finalReturn()\n",
        "\n",
        "    return self.word\n",
        "\n",
        "  def step3(self):\n",
        "\n",
        "    for r in range(1,len(self.inflectedWord)-1):\n",
        "      if self.word[:r] in globalPrefixWordsSet and (self.word[r:] in totalWords or self.word[r:] in globalRootWordsSet):\n",
        "        self.possibleRootWords.add(WordLemmatizer(self.word[r:]).lemmatize())\n",
        "    if(len(self.possibleRootWords)):\n",
        "      return self.finalReturn()\n",
        "\n",
        "    return self.word\n",
        "\n",
        "  def finalReturn(self):\n",
        "    # currently here returning longest one\n",
        "    possibleRootWords = list(self.possibleRootWords)\n",
        "    possibleRootWords.sort(key = lambda x: -len(x))\n",
        "\n",
        "    if possibleRootWords and len(possibleRootWords[0])>2:\n",
        "      return possibleRootWords[0]\n",
        "\n",
        "    return self.word\n",
        "\n",
        "def sanitizeLine(line):\n",
        "  return re.sub(r'\\s+', ' ', re.sub(r'[{}[\\]:;?@!#$%^&*()-_\\'\\\"<>\\u0964\\u0965,]', ' ', line.encode(\"utf-8\").decode(\"utf-8\"))).split()\n",
        "\n",
        "def processWord(word):\n",
        "\n",
        "  if word in alreadyLemmatizedWords:\n",
        "    return alreadyLemmatizedWords[word]\n",
        "\n",
        "  lemma= WordLemmatizer(word).lemmatize()\n",
        "  alreadyLemmatizedWords[word]=lemma\n",
        "  return lemma\n",
        "\n",
        "def lemmatize(line):\n",
        "  # this is the function that will be called by the user to lemmatize hindi text, it can accept both word and a line\n",
        "  words = sanitizeLine(line)\n",
        "\n",
        "  return \" \".join([processWord(word) for word in words if word])"
      ],
      "metadata": {
        "id": "DW-vAUAiyCSZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# line = \"वक्त की मार से हमेशा डर कर रहो क्योंकि बुरा वक्त कभी पूछ कर नहीं आता।\"\n",
        "# line = \"जिन्दगी से जुड़ी सच्ची बातें\"\n",
        "line = \"जो आपके सीखने की क्षमता है वह एक उपहार है, जो आपके सीखने की योग्यता है वह आपका कौशल है और आपके सीखने की इच्छा एक विकल्प है।\"\n",
        "line = \"कार्यालय में विभिन्न विभागों की टीमें सहयोग करके समस्याओं का समाधान कर रही हैं। उनके योगदान से कंपनी के उद्देश्यों को पूरा करने में मदद मिलती है। आपूर्ति श्रृंखला को निरंतर सुधारते हुए, गुणवत्ता नियंत्रण प्रक्रिया को मजबूत किया जाता है। यह सुनिश्चित करने के लिए कि उत्पादों का मानक अनुरूप है और ग्राहकों को संतुष्ट किया जा सके। विपणन और प्रचार के माध्यम से, व्यापार का प्रशंसा किया जाता है और नए ग्राहकों को प्रवर्धित करने का प्रयास किया जाता है।\"\n",
        "print(lemmatize(line))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q57WF6OWW7Ug",
        "outputId": "35f0b46b-d71e-4e84-a9cc-17becffd1179"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "कार्यालय में विभिन्न विभाग की टीम सहयोग कर समस्या का समाधान कर रह है उनके योग से कंपनी के उद्देश्य को पूरा कर में मदद मिल है आपूर्ति श्रृंखला को निरंतर सुधार हो गुण नियंत्रण प्रक्रिया को मजबूत कर जा है यह सुन कर के ले कि उत्पाद का मान अनुरूप है और ग्राहक को संतुष्ट कर जा सक विपणन और प्र के माध्यम से व्यापार का प्रशंसा कर जा है और नए ग्राहक को प्रवर्ध कर का प्रयास कर जा है\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install hindilemmatizer\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EsgB1CtuT-iF",
        "outputId": "de260059-ba5b-4f63-d1bb-90fbc3d1bba3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: hindilemmatizer in /usr/local/lib/python3.10/dist-packages (0.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from hindilemmatizer import lemmatizer\n",
        "\n",
        "print(lemmatizer.lemmatize(\"जो आपके सीखने की क्षमता है वह एक उपहार है, जो आपके सीखने की योग्यता है वह आपका कौशल है और आपके सीखने की इच्छा एक विकल्प है।\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uc2CCw-mUTMs",
        "outputId": "cd82f623-a00d-412c-da91-c82e7406da2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "जो आपके सीख की क्षमता है वह एक उपह है जो आपके सीख की योग है वह आपका कौशल है और आपके सीख की इच्छा एक विकल्प है\n"
          ]
        }
      ]
    }
  ]
}